{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data = pd.read_csv('traindata.csv')\n",
    "data = data.drop(['id','price','date', 'price/sqft', 'rootprice/sqft'], axis=1)\n",
    "X_train = data.drop(['log price'], axis=1)\n",
    "y_train = data['log price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  0.03261539087442806\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "# Evaluate the model using mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}\n",
      "Best score:  0.8870218299424002\n"
     ]
    }
   ],
   "source": [
    "model_params = GradientBoostingRegressor()\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 20, 30, 40, 50],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'max_depth': [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model_params, param_grid=param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41890376, 0.58603404, 0.66671414, 0.71446623, 0.74416486,\n",
       "       0.56932325, 0.71344514, 0.77658016, 0.81011874, 0.82981681,\n",
       "       0.64028479, 0.78025762, 0.82907096, 0.85011531, 0.86068268,\n",
       "       0.68375602, 0.81780043, 0.85607997, 0.87014767, 0.87717178,\n",
       "       0.71185232, 0.83913561, 0.8717228 , 0.8822109 , 0.88702183,\n",
       "       0.0595557 , 0.11405791, 0.16357039, 0.20870688, 0.2498011 ,\n",
       "       0.10367686, 0.18941452, 0.26312824, 0.32629077, 0.38037841,\n",
       "       0.12077991, 0.22198022, 0.3072733 , 0.37853349, 0.43885011,\n",
       "       0.12991901, 0.23908897, 0.3309606 , 0.40793716, 0.47227386,\n",
       "       0.13767878, 0.25272712, 0.34863293, 0.42866813, 0.49587143,\n",
       "       0.00553815, 0.01185075, 0.01798269, 0.02406401, 0.03011629,\n",
       "       0.01045403, 0.02157961, 0.03248824, 0.04320019, 0.05373741,\n",
       "       0.01221548, 0.02512491, 0.03779412, 0.05022912, 0.06242837,\n",
       "       0.01320287, 0.02707903, 0.04071281, 0.0541084 , 0.0672445 ,\n",
       "       0.01407554, 0.028786  , 0.04321473, 0.05737752, 0.07128452])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}\n",
      "Best score:  0.8870218299424002\n"
     ]
    }
   ],
   "source": [
    "model_best_params = GradientBoostingRegressor()\n",
    "param_grid = {\n",
    "    'n_estimators': [grid_search.best_params_['n_estimators']],\n",
    "    'learning_rate': [grid_search.best_params_['learning_rate']],\n",
    "    'max_depth': [grid_search.best_params_['max_depth']]\n",
    "}\n",
    "\n",
    "grid_search_best = GridSearchCV(estimator=model_params, param_grid=param_grid)\n",
    "grid_search_best.fit(X_train, y_train)\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = model.feature_importances_\n",
    "feature_names = data.columns.to_list()\n",
    "index = feature_names.index('log price')\n",
    "del feature_names[index]\n",
    "del feature_importances[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m feature_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m      2\u001b[0m feature_df[\u001b[39m'\u001b[39m\u001b[39mimportance\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m feature_importances\n\u001b[0;32m----> 3\u001b[0m feature_df[\u001b[39m'\u001b[39m\u001b[39mfeature\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m feature_names[\u001b[39m1\u001b[39;49m::]\n\u001b[1;32m      5\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m, \u001b[39m6\u001b[39m))\n\u001b[1;32m      6\u001b[0m plt\u001b[39m.\u001b[39mbar(feature_df[\u001b[39m'\u001b[39m\u001b[39mfeature\u001b[39m\u001b[39m'\u001b[39m], feature_df[\u001b[39m'\u001b[39m\u001b[39mimportance\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "feature_df = pd.DataFrame()\n",
    "feature_df['importance'] = feature_importances\n",
    "feature_df['feature'] = feature_names[1::]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(feature_df['feature'], feature_df['importance'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostRegressor()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error: \", mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
